{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca90d741-9d9b-4f25-92bf-67315c0faea6",
   "metadata": {},
   "source": [
    "# Predicting train delays and detecting unusual service patterns\n",
    "\n",
    "This project will specifically focus on passenger train services either stopping at, starting, or passing through Reading. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895729c-df34-4e45-94a6-32eec75c951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, date, timedelta\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from modules.data_skew import numeric_col_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb71e88-21c1-45d4-8515-9c9420c96ff0",
   "metadata": {},
   "source": [
    "## Reading in and cleaning service data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_companies = {\n",
    "    'Great Western Railway': [800, 802, 387, 175, 165, 166, 57, 150, 158],\n",
    "    'Elizabeth Line': [345],\n",
    "    'Cross Country': [220, 221],\n",
    "    'South Western Railway': [455, 444, 450, 458, 701, 159]\n",
    "}\n",
    "\n",
    "# Convert `train_companies` dict to DataFrames\n",
    "train_companies_df = pd.DataFrame(list(train_companies.items()), columns=['company', 'train_numbers'])\n",
    "\n",
    "# Explode to have one train number per row\n",
    "train_companies_df = train_companies_df.explode('train_numbers').rename(columns={'train_numbers': 'lead_class'}).reset_index(drop=True)\n",
    "train_companies_df['lead_class'] = train_companies_df['lead_class'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "service_data = pd.read_csv(r\"C:\\Users\\fcpen\\Documents\\GitHub\\Train_delays_and_services\\data\\RDG_2024-2025_ALL.csv\")\n",
    "service_data = service_data[(service_data['transport_type'] == 'train') & (service_data['lead_class'] != 66)] # only interested in passenger train services\n",
    "service_data.drop(columns=['transport_type', 'this_tiploc', 'this_crs'], inplace=True)\n",
    "\n",
    "non_passenger_pattern = r'Siding|Sdgs|Sidings|Loop|Yard|Depot|Quarry|Freight|Freightliners|Reception|Recep|Receptions|Railhead|Jn|Terminal|Terminl|Refinery|Staff|Tml|Recp|Yd|F.L.T|Fuelling|Gbrf|T.C|Works|Tarmac|Trsmd|Docks|Fh|Dock|Fhh|M.C.T|Sdg|Cargo|Waste'\n",
    "service_data = service_data[~service_data['origin_description'].str.contains(non_passenger_pattern, case=False, na=False, regex=True)]\n",
    "service_data = service_data[~service_data['destination_description'].str.contains(non_passenger_pattern, case=False, na=False, regex=True)]\n",
    "service_data = service_data[service_data['origin_description'] != service_data['destination_description']] # only want services that are going to a destination\n",
    "\n",
    "service_data = service_data.merge(train_companies_df, on='lead_class', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcccb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date columns to datetime\n",
    "service_data['run_date'] = pd.to_datetime(service_data['run_date'], format='%d/%m/%Y')\n",
    "\n",
    "date_cols = ['gbtt_arr', 'gbtt_dep', 'actual_arr', 'actual_dep', 'wtt_pass', 'actual_pass', 'wtt_arr', 'wtt_dep']\n",
    "for col in date_cols:\n",
    "    service_data[col] = pd.to_datetime(service_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5eeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4035a",
   "metadata": {},
   "source": [
    "One thing that I have noticed is that the run date indicates the date that the train left the origin station which sometimes leads to mismatches late at night; for feature engineering I'll use the date it's at Reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14059c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date for the service based on WTT times (arrival, dep, pass) using the first available\n",
    "# Fall back to actual times if none of the WTT values are present.\n",
    "cols_priority = ['wtt_arr', 'wtt_dep', 'wtt_pass', 'actual_arr', 'actual_dep', 'actual_pass']\n",
    "\n",
    "# Build a datetime column using the first non-null value in the priority list\n",
    "service_data['reading_datetime'] = service_data[cols_priority].bfill(axis=1).iloc[:, 0]\n",
    "\n",
    "# Extract date as a normalized datetime version (midnight) for grouping\n",
    "service_data['Reading_date'] = service_data['reading_datetime'].dt.normalize()\n",
    "\n",
    "# Quick check\n",
    "service_data[['wtt_arr','wtt_dep','wtt_pass','Reading_date', 'reading_datetime']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb627d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee344ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data[service_data['num_vehicles'] > 12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb9422",
   "metadata": {},
   "source": [
    "The missing values in the datetime columns are likely due to factors to do with the nature of the service itself, so I will ignore those missing values, or in the case of the delays in minutes, I'll replace any nulls with zeroes. As there are so few trains with a missing platform number, I will drop those rows. For train company and number of carriages and train class, I will use domain knowledge of which train company runs services between those two stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37959347",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.dropna(subset=['platform', 'platform_actual'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60695ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['actual_arr_delay_mins', 'actual_dep_delay_mins', 'actual_pass_delay_mins']\n",
    "\n",
    "service_data.fillna({col: 0 for col in selected_cols},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51086b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_company(origin: str, destination: str):\n",
    "    \"\"\"\n",
    "    Determine the train company from origin and destination strings.\n",
    "\n",
    "    Returns the company name as a string, or `None` if it cannot be inferred.\n",
    "    \"\"\"\n",
    "    # guard against non-string inputs\n",
    "    if not isinstance(origin, str) or not isinstance(destination, str):\n",
    "        return None\n",
    "\n",
    "    origin = origin.strip()\n",
    "    destination = destination.strip()\n",
    "\n",
    "    el_stations = {'Abbey Wood', 'London Liverpool Street', 'Shenfield'}\n",
    "    xc_stations = {'Birmingham New Street', 'Manchester Piccadilly', 'Bournemouth', 'York', 'Banbury'}\n",
    "\n",
    "    # Elizabeth Line when one end is Reading and the other is one of the EL stations\n",
    "    if destination in el_stations or origin in el_stations:\n",
    "        return 'Elizabeth Line'\n",
    "\n",
    "    # Great Western Railway when Paddington is involved\n",
    "    if origin == 'London Paddington' and destination != 'Reading':\n",
    "        return 'Great Western Railway'\n",
    "    \n",
    "    if destination == 'London Paddington':\n",
    "        return 'Great Western Railway'\n",
    "    \n",
    "    if origin in xc_stations or destination in xc_stations:\n",
    "        return 'Cross Country'\n",
    "    \n",
    "    if destination == 'London Victoria' or origin == 'London Victoria':\n",
    "        return 'South Western Railway'\n",
    "    # Unable to determine\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c82e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply `train_company` to rows with missing `company` and show results\n",
    "before = service_data['company'].isnull().sum()\n",
    "mask = service_data['company'].isnull()\n",
    "service_data.loc[mask, 'company'] = (\n",
    "    service_data.loc[mask].apply(\n",
    "        lambda r: train_company(r['origin_description'], r['destination_description']), axis=1\n",
    "    )\n",
    ")\n",
    "after = service_data['company'].isnull().sum()\n",
    "print(f'Company missing before: {before}, after: {after}')\n",
    "\n",
    "# Show remaining ambiguous rows for manual review\n",
    "service_data[service_data['company'].isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b805327",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data['company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38fb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in null companies with the most common company - Great Western Railway\n",
    "service_data.fillna({'company': 'Great Western Railway'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b33cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb31186",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data[service_data['actual_arr_delay_mins'] < -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data['was_delayed'] = (service_data['actual_arr_delay_mins'] > 0) | (service_data['actual_dep_delay_mins'] > 0) | (service_data['actual_pass_delay_mins'] > 0)\n",
    "service_data['was_cancelled'] = service_data['stp_indicator'] == 'CAN'\n",
    "service_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['actual_arr_delay_mins', 'actual_dep_delay_mins', 'actual_pass_delay_mins', 'num_vehicles']\n",
    "\n",
    "numeric_col_distributions(service_data, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f4d7b",
   "metadata": {},
   "source": [
    "As expected, the various train delay columns are very skewed as the majority of trains aren't delayed from Reading. The number of carriages is not very skewed as most trains have standard configurations, and there's only so long a station platform can be; from the histogram one can see that there are very very few trains that are longer than 12 carriages, as very few platforms can accommodate trains longer than 12 carriages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7b847",
   "metadata": {},
   "source": [
    "## Reading in weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e02386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define your parameters\n",
    "latitude = 51.458786  \n",
    "longitude = -0.971828\n",
    "start_date = \"2024-12-17\"\n",
    "end_date = \"2025-12-18\"\n",
    "# List of hourly variables you want. See full list in docs.\n",
    "hourly_variables = [\"temperature_2m\", \"precipitation\", \"rain\", \"snowfall\", \"snow_depth\", \"cloud_cover\", \"cloud_cover_low\", \"cloud_cover_mid\", \"cloud_cover_high\"]\n",
    "\n",
    "# 2. Construct the API URL\n",
    "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "params = {\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"start_date\": start_date,\n",
    "    \"end_date\": end_date,\n",
    "    \"hourly\": \",\".join(hourly_variables),\n",
    "    \"timezone\": \"auto\", # Automatically adjusts timestamps to local time.\n",
    "    \"wind_speed_unit\": \"mph\"\n",
    "}\n",
    "\n",
    "# 3. Make the API request\n",
    "print(\"Downloading weather data...\")\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# 4. Convert JSON to a Pandas DataFrame and save as CSV\n",
    "weather_data = pd.DataFrame(data=data[\"hourly\"])\n",
    "weather_data['Reading_date'] = pd.to_datetime(weather_data['time']).dt.normalize()\n",
    "weather_data['hour_of_day'] = pd.to_datetime(weather_data['time']).dt.hour\n",
    "\n",
    "print(f\"Total records: {len(weather_data)}\")\n",
    "weather_data.head()\n",
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0b54d4",
   "metadata": {},
   "source": [
    "## Initial analysis by train company\n",
    "\n",
    "- Which companies have the most delays?\n",
    "- Which companies have the most severe delays?\n",
    "- Which companies have the most cancellations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5367cb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "delayed_trains_company = service_data.groupby('company').agg({'was_delayed': 'sum', 'company': 'count'}).rename(columns={'was_delayed': 'num_delayed_trains', 'company': 'total_trains'})\n",
    "delayed_trains_company['proportion_delayed'] = delayed_trains_company['num_delayed_trains'] / delayed_trains_company['total_trains']\n",
    "delayed_trains_company.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e105a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=service_data, x='company', hue='was_delayed', order=service_data[service_data['was_delayed'] == True]['company'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Train Company')\n",
    "plt.ylabel('Number of Delayed Trains')\n",
    "plt.title('Number of Delayed Trains by Company')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a446074",
   "metadata": {},
   "source": [
    "As expected, Great Western Railway (GWR) shows by far the most delays, however, a lot of the trains at Reading station are GWR trains.  Cross Country has the highest proportion of delays with over half of its trains being delayed. The Elizabeth line has the lowest proportion of trains delayed; I suspect this is potentially due to it being a much newer line compared to the rest and also covering less distance compared to some GWR trains and Cross Country trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelled_trains_company = service_data.groupby('company').agg({'was_cancelled': 'sum', 'company': 'count'}).rename(columns={'was_cancelled': 'num_cancelled_trains', 'company': 'total_trains'})\n",
    "cancelled_trains_company['proportion_cancelled'] = cancelled_trains_company['num_cancelled_trains'] / cancelled_trains_company['total_trains']\n",
    "cancelled_trains_company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f929f9",
   "metadata": {},
   "source": [
    "Great Western Railways has the highest proportion of cancelled trains followed by the Elizabeth line and Cross Country. South Western Railway has an extremely low proportion of cancelled services at only 0.05%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aacbbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifically looking at the severity of delays when trains are delayed\n",
    "\n",
    "avg_delay_by_company = service_data[service_data['was_delayed'] == True].groupby('company').agg({'actual_arr_delay_mins': 'mean', 'actual_dep_delay_mins': 'mean', 'actual_pass_delay_mins': 'mean'}).rename(columns={\n",
    "    'actual_arr_delay_mins': 'avg_arr_delay',\n",
    "    'actual_dep_delay_mins': 'avg_dep_delay',\n",
    "    'actual_pass_delay_mins': 'avg_pass_delay'\n",
    "})\n",
    "avg_delay_by_company.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9519e5",
   "metadata": {},
   "source": [
    "For viewing the severity of delays per train operator, I decided to stick with looking at trains that were delayed as I wanted to assess the severity of delays when they do occur. Overall, Cross Country has the highest level of delays amongst delayed trains and the Elizabeth line has the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee47069",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(service_data[numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ce774",
   "metadata": {},
   "source": [
    "There's a strong correlation between arrival delay and departure delay, which makes sense as if a train arrives late then it will leave late as well. There's hardly any correlation between the number of carriages and the departure delay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e82f05",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_bank_holiday(date):\n",
    "    \"\"\"\n",
    "    This functions returns a boolean if a date is a UK bank holiday\n",
    "    \"\"\"\n",
    "\n",
    "    uk_bank_holidays_2025 = [\n",
    "        date(2025, 1, 1),   # New Year's Day\n",
    "        date(2025, 4, 18),  # Good Friday\n",
    "        date(2025, 4, 21),  # Easter Monday\n",
    "        date(2025, 5, 5),   # Early May Bank Holiday\n",
    "        date(2025, 5, 26),  # Spring Bank Holiday\n",
    "        date(2025, 8, 25),  # Summer Bank Holiday\n",
    "    ]\n",
    "\n",
    "    if date in uk_bank_holidays_2025:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ee16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_bank_holidays_2025 = [\n",
    "        date(2025, 1, 1),   # New Year's Day\n",
    "        date(2025, 4, 18),  # Good Friday\n",
    "        date(2025, 4, 21),  # Easter Monday\n",
    "        date(2025, 5, 5),   # Early May Bank Holiday\n",
    "        date(2025, 5, 26),  # Spring Bank Holiday\n",
    "        date(2025, 8, 25),  # Summer Bank Holiday\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(month):\n",
    "    \"\"\"\n",
    "    This takes months and assigns a season.\n",
    "\n",
    "    Arg: month\n",
    "\n",
    "    Return: a string corresponding to which season the train was run in\n",
    "    \"\"\"\n",
    "    if month in [12, 1, 2]: return 'Winter' #Assuming December, January, February as winter\n",
    "    elif month in [3, 4, 5]: return 'Spring'\n",
    "    elif month in [6, 7, 8]: return 'Summer' \n",
    "    else: return 'Autumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting hour of day, day of the week, \n",
    "service_data['hour_of_day'] = service_data['reading_datetime'].dt.hour\n",
    "service_data['day_of_week'] = service_data['reading_datetime'].dt.dayofweek #Monday = 0\n",
    "service_data['month'] = service_data['reading_datetime'].dt.month\n",
    "service_data['season'] = service_data['month'].apply(get_season)\n",
    "\n",
    "\n",
    "service_data['is_bank_holiday'] = service_data['Reading_date'].isin(uk_bank_holidays_2025)\n",
    "service_data['is_weekday'] = service_data['day_of_week'].isin([0, 1, 2, 3, 4])\n",
    "\n",
    "# Build safely in steps to avoid any operator-precedence or ambiguous-truth issues\n",
    "is_weekday = service_data['is_weekday']\n",
    "is_not_bank = ~service_data['is_bank_holiday']\n",
    "is_peak_hours = ((service_data['hour_of_day'].between(7, 9)) | (service_data['hour_of_day'].between(16, 18)))\n",
    "\n",
    "service_data['is_peak_time'] = is_weekday & is_not_bank & is_peak_hours\n",
    "\n",
    "service_data.drop(columns=['reading_datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba016591",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.info()\n",
    "service_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_weather_data = service_data.merge(\n",
    "    weather_data,\n",
    "    on=['Reading_date', 'hour_of_day'],\n",
    "    how='left'\n",
    "    )\n",
    "service_weather_data.info()\n",
    "service_weather_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770feec1",
   "metadata": {},
   "source": [
    "## Predicting delays and cancellations\n",
    "\n",
    "For these predictions I'll be focusing on trains that stopped at Reading or were due to stop at Reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1e461",
   "metadata": {},
   "source": [
    "### Predicting if a train will be delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee929eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_weather_data['was_delayed'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09570125",
   "metadata": {},
   "source": [
    "### Predicting how delayed a train will be \n",
    "\n",
    "For this I'll be focusing on predicting how delayed an already delayed train is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f5082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0363ac19",
   "metadata": {},
   "source": [
    "### Predicting if a train will be cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_weather_data['was_cancelled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aefbe24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
