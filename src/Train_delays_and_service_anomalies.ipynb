{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca90d741-9d9b-4f25-92bf-67315c0faea6",
   "metadata": {},
   "source": [
    "# Predicting train delays and detecting unusual service patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895729c-df34-4e45-94a6-32eec75c951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, date, timedelta\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from modules.data_skew import numeric_col_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb71e88-21c1-45d4-8515-9c9420c96ff0",
   "metadata": {},
   "source": [
    "## Reading in and cleaning service data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_companies = {\n",
    "    'Great Western Railway': [800, 802, 387, 175, 165, 166, 57, 150, 158],\n",
    "    'Elizabeth Line': [345],\n",
    "    'Cross Country': [220, 221],\n",
    "    'South Western Railway': [455, 444, 450, 458, 701, 159]\n",
    "}\n",
    "\n",
    "# Convert `train_companies` dict to DataFrames\n",
    "train_companies_df = pd.DataFrame(list(train_companies.items()), columns=['company', 'train_numbers'])\n",
    "\n",
    "# Explode to have one train number per row\n",
    "train_companies_df = train_companies_df.explode('train_numbers').rename(columns={'train_numbers': 'lead_class'}).reset_index(drop=True)\n",
    "train_companies_df['lead_class'] = train_companies_df['lead_class'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "service_data = pd.read_csv(r\"C:\\Users\\fcpen\\Documents\\GitHub\\Train_delays_and_services\\data\\RDG_2024-2025_ALL.csv\")\n",
    "service_data = service_data[(service_data['transport_type'] == 'train') & (service_data['lead_class'] != 66)] # only interested in passenger train services\n",
    "service_data.drop(columns=['transport_type', 'this_tiploc', 'this_crs'], inplace=True)\n",
    "\n",
    "non_passenger_pattern = r'Siding|Sdgs|Sidings|Loop|Yard|Depot|Quarry|Freight|Freightliners|Reception|Recep|Receptions|Railhead|Jn|Terminal|Terminl|Refinery|Staff|Tml|Recp|Yd|F.L.T|Fuelling|Gbrf|T.C|Works|Tarmac|Trsmd|Docks|Fh|Dock|Fhh|M.C.T|Sdg|Cargo|Waste'\n",
    "service_data = service_data[~service_data['origin_description'].str.contains(non_passenger_pattern, case=False, na=False, regex=True)]\n",
    "service_data = service_data[~service_data['destination_description'].str.contains(non_passenger_pattern, case=False, na=False, regex=True)]\n",
    "service_data['was_cancelled'] = service_data['stp_indicator'] == 'CAN'\n",
    "\n",
    "service_data = service_data.merge(train_companies_df, on='lead_class', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5eeba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb627d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee344ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820db1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data[service_data['num_vehicles'] > 12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb9422",
   "metadata": {},
   "source": [
    "The missing values in the datetime columns are likely due to factors to do with the nature of the service itself, so I will ignore those missing values, or in the case of the delays in minutes, I'll replace any nulls with zeroes. As there are so few trains with a missing platform number, I will drop those rows. For train company and number of carriages and train class, I will use domain knowledge of which train company runs services between those two stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37959347",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.dropna(subset=['platform', 'platform_actual'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60695ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['actual_arr_delay_mins', 'actual_dep_delay_mins', 'actual_pass_delay_mins']\n",
    "\n",
    "service_data.fillna({col: 0 for col in selected_cols},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51086b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_company(origin: str, destination: str):\n",
    "    \"\"\"\n",
    "    Determine the train company from origin and destination strings.\n",
    "\n",
    "    Returns the company name as a string, or `None` if it cannot be inferred.\n",
    "    \"\"\"\n",
    "    # guard against non-string inputs\n",
    "    if not isinstance(origin, str) or not isinstance(destination, str):\n",
    "        return None\n",
    "\n",
    "    origin = origin.strip()\n",
    "    destination = destination.strip()\n",
    "\n",
    "    el_stations = {'Abbey Wood', 'London Liverpool Street', 'Shenfield'}\n",
    "    xc_stations = {'Birmingham New Street', 'Manchester Piccadilly', 'Bournemouth', 'York', 'Banbury'}\n",
    "\n",
    "    # Elizabeth Line when one end is Reading and the other is one of the EL stations\n",
    "    if destination in el_stations or origin in el_stations:\n",
    "        return 'Elizabeth Line'\n",
    "\n",
    "    # Great Western Railway when Paddington is involved\n",
    "    if origin == 'London Paddington' and destination != 'Reading':\n",
    "        return 'Great Western Railway'\n",
    "    \n",
    "    if destination == 'London Paddington':\n",
    "        return 'Great Western Railway'\n",
    "    \n",
    "    if origin in xc_stations or destination in xc_stations:\n",
    "        return 'Cross Country'\n",
    "    \n",
    "    if destination == 'London Victoria' or origin == 'London Victoria':\n",
    "        return 'South Western Railway'\n",
    "    # Unable to determine\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c82e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply `train_company` to rows with missing `company` and show results\n",
    "before = service_data['company'].isnull().sum()\n",
    "mask = service_data['company'].isnull()\n",
    "service_data.loc[mask, 'company'] = (\n",
    "    service_data.loc[mask].apply(\n",
    "        lambda r: train_company(r['origin_description'], r['destination_description']), axis=1\n",
    "    )\n",
    ")\n",
    "after = service_data['company'].isnull().sum()\n",
    "print(f'Company missing before: {before}, after: {after}')\n",
    "\n",
    "# Show remaining ambiguous rows for manual review\n",
    "service_data[service_data['company'].isnull()].head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b805327",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data['company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38fb233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in null companies with the most common company - Great Western Railway\n",
    "service_data.fillna({'company': 'Great Western Railway'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b33cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb31186",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_data[service_data['actual_dep_delay_mins'] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['actual_arr_delay_mins', 'actual_dep_delay_mins', 'actual_pass_delay_mins', 'num_vehicles']\n",
    "\n",
    "numeric_col_distributions(service_data, numerical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f4d7b",
   "metadata": {},
   "source": [
    "As expected, the various train delay columns are very skewed as the majority of trains aren't delayed from Reading. The number of carriages is not very skewed as most trains have standard configurations, and there's only so long a station platform can be; from the histogram one can see that there are very very few trains that are longer than 12 carriages, as very few platforms can accommodate trains longer than 12 carriages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# services_per_day = service_data.groupby('run_date')['schedule_uid'].agg('count')\n",
    "\n",
    "# plt.figure(figsize=(14, 10))\n",
    "# services_per_day.plot(kind='line')\n",
    "# plt.title('Services per day', fontsize=13, fontweight='bold')\n",
    "# plt.ylabel('Number of services')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
